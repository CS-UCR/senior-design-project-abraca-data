{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '2021_12_07.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mr/mwsr6_lj70d61ys4kkzgnhnh0000gn/T/ipykernel_5826/865614011.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"2021_12_07.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"start_date\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end_date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'work_postal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"comprate_2021-12-07-10-26-31.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Replace under_29 by .under_29 to make it easier when sorting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '2021_12_07.csv'"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv(\"../data/2021_12_07.csv\", parse_dates = [\"start_date\", \"end_date\"], dtype={'work_postal':'str'})\n",
    "df2 = pd.read_csv(\"comprate_2021-12-07-10-26-31.csv\")\n",
    "\n",
    "#Replace under_29 by .under_29 to make it easier when sorting\n",
    "df['age_group'] = df['age_group'].replace(to_replace='under_29', value='.under_29')\n",
    "\n",
    "#Fill in na values for age_group\n",
    "df['age_group'] = df['age_group'].fillna(df['age_group'].value_counts().index[0])\n",
    "\n",
    "#Replace missing values in event column with unknown\n",
    "df['event'] = df['event'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather relevant features from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporary end_date: this end date is used if the employee is still working\n",
    "temp_end_date = pd.to_datetime('2021-12-07')\n",
    "\n",
    "#Get the list of all employees by their unique IDs\n",
    "employee_ids = df.emplid_sec.unique()\n",
    "\n",
    "duration = []                #total duration of employment in days\n",
    "division = []                #last division employed at\n",
    "department = []              #last department employed at\n",
    "comprate = []                #highest comprate during employment\n",
    "last_pay_raise = []          #days since highest comprate\n",
    "highest_educ_lvl = []        #highest education level\n",
    "age_group = []               #age group\n",
    "pay_increase_ot = []         #(max comprate - min comprate) / duration\n",
    "last_jobtitle_duration = []  #duration of last held jobtitle in days\n",
    "highest_jt = []              #\n",
    "event = []                   #Unknown, Retirement, Termination\n",
    "#Loop through each employee records\n",
    "for ID in employee_ids:\n",
    "    #Get all records of the employee\n",
    "    employee = df[df['emplid_sec'] == ID].copy()\n",
    "    \n",
    "    ##### DURATION #####\n",
    "    #number of days worked as of 2021-12-07 (Includes end date)\n",
    "    duration.append(int(sum(employee['duration'].tolist(), employee.shape[0])))\n",
    "    \n",
    "    ##### DIVISION #####\n",
    "    #Get the last division they were in\n",
    "    employee.sort_values(by=['end_date'], inplace=True)\n",
    "    division.append(employee.iloc[-1]['division'])\n",
    "    \n",
    "    ##### DEPARTMENT #####\n",
    "    #Get the last department they were in\n",
    "    employee.sort_values(by=['end_date'], inplace=True)\n",
    "    department.append(employee.iloc[-1]['department'])\n",
    "    \n",
    "    ##### COMP RATE #####\n",
    "    #Get their highest comprate\n",
    "    comprate.append(max(employee['comprate'].tolist()))\n",
    "    \n",
    "    ##### LAST PAY RAISE #####\n",
    "    #Get last date of work or temporary last date\n",
    "    if(employee['end_date'].isna().sum()):\n",
    "        end = temp_end_date\n",
    "    else:\n",
    "        end = employee['end_date'].sort_values().tolist()[-1]\n",
    "    #Get date of last pay raise\n",
    "    employee.sort_values(by=['comprate'], inplace=True)\n",
    "    last_raise = employee.iloc[-1]['start_date']\n",
    "    #Calculate the difference\n",
    "    last_pay_raise.append((end - last_raise).days)\n",
    "    \n",
    "    ##### EDUCATION LEVEL #####\n",
    "    #Get the highest education level\n",
    "    highest_educ_lvl.append(sorted(employee['highest_educ_lvl'].tolist())[-1])\n",
    "    \n",
    "    ##### AGE GROUP #####\n",
    "    #Get the age group they were before they left\n",
    "    age_group.append(sorted(employee['age_group'].tolist())[-1])\n",
    "    \n",
    "    ##### COMPRATE INCREASE OVER TIME #####\n",
    "    #(max - min) / duration\n",
    "    max_rate = max(employee['comprate'].tolist())\n",
    "    min_rate = min(employee['comprate'].tolist())\n",
    "    pay_increase_ot.append((max_rate - min_rate) / duration[-1])\n",
    "    \n",
    "    ##### DURATION OF CURRENT POSITION #####\n",
    "    #Get the duration in days of the last jobtitle they held or currently holding\n",
    "    employee.sort_values(by=['end_date'], inplace=True)\n",
    "    last_jobtitle = employee.iloc[-1]['jobtitle']\n",
    "    last_jobtitle_duration.append(employee.iloc[-1]['duration'] + 1)\n",
    "    for i in reversed(range(len(employee) - 1)):\n",
    "        if(employee.iloc[i]['jobtitle'] == last_jobtitle):\n",
    "            last_jobtitle_duration[-1] += employee.iloc[i]['duration'] + 1\n",
    "        else:\n",
    "            break\n",
    "    ##### EVENT #####\n",
    "    #Get the employee's latest event\n",
    "    #Unknown, Retirement, Termination\n",
    "    employee.sort_values(by=['end_date'], inplace=True)\n",
    "    event.append(employee.iloc[-1]['event'])\n",
    "\n",
    "piot_compared_avg = []  #pay increase over time compared with average\n",
    "\n",
    "#Get the average comprate increase over time\n",
    "avg_pay_increase_ot = sum(pay_increase_ot) / len(pay_increase_ot)\n",
    "\n",
    "##### COMPRATE INCREASE OVER TIME COMPARED TO AVERAGE #####\n",
    "#calculate the % below or above average\n",
    "for val in pay_increase_ot:\n",
    "    piot_compared_avg.append((val - avg_pay_increase_ot) / avg_pay_increase_ot)\n",
    "#Current technique: calculate the average comprate for each jobtitle and sort by the average for its rank\n",
    "\n",
    "#Get all current jobtitles\n",
    "jobtitles = df['jobtitle'].unique()\n",
    "\n",
    "#Dictionary to store average\n",
    "pay_avg_by_jt = {}\n",
    "\n",
    "#Loop through each jobtitles\n",
    "for jt in jobtitles:\n",
    "    #Get all records with the current jobtitle\n",
    "    records = df[df['jobtitle'] == jt].copy()\n",
    "    #Get the maximum comprate for each employee\n",
    "    max_comprates_by_jt = records.groupby(['emplid_sec'])['comprate'].max()\n",
    "    #Calculate the average\n",
    "    pay_avg_by_jt[jt] = sum(max_comprates_by_jt) / len(max_comprates_by_jt)\n",
    "    \n",
    "\n",
    "#Loop through each employees\n",
    "for ID in employee_ids:\n",
    "    #Get all records of the employee\n",
    "    employee = df[df['emplid_sec'] == ID].copy()\n",
    "    \n",
    "    ##### HIGHEST JOB TITLE #####\n",
    "    #Get all jobtitles\n",
    "    jobs = employee['jobtitle'].unique().tolist()\n",
    "    max_rate = 0; #Variable to store the maximum comparate\n",
    "    highest_jt.append(\"\")\n",
    "    #Loop through each jobtitles\n",
    "    for j in jobs:\n",
    "        #Compare the comprate and keep the max\n",
    "        if(pay_avg_by_jt[j] > max_rate):\n",
    "            max_rate = pay_avg_by_jt[j]\n",
    "            highest_jt[-1] = j\n",
    "\n",
    "assert(len(duration) ==             \n",
    "len(division) ==               \n",
    "len(department) ==               \n",
    "len(comprate) ==                \n",
    "len(last_pay_raise) ==          \n",
    "len(highest_educ_lvl) ==        \n",
    "len(age_group) ==               \n",
    "len(pay_increase_ot) ==         \n",
    "len(last_jobtitle_duration) ==  \n",
    "len(piot_compared_avg) ==       \n",
    "len(event))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode/convert data to integer values or one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#encode class values as integers\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "\n",
    "age_group = LabelEncoder().fit_transform(age_group)\n",
    "division = LabelEncoder().fit_transform(division)\n",
    "event = LabelEncoder().fit_transform(event)\n",
    "highest_educ_lvl = LabelEncoder().fit_transform(highest_educ_lvl)\n",
    "\n",
    "Y = event\n",
    "vals = pd.DataFrame()\n",
    "vals['duraton'] = duration\n",
    "vals['comprate'] = comprate\n",
    "vals['age_group'] = age_group\n",
    "vals['division'] = division\n",
    "vals['last_pay_raise'] = last_pay_raise\n",
    "dataset = vals.values\n",
    "\n",
    "X = dataset[:,0:5].astype(float)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mr/mwsr6_lj70d61ys4kkzgnhnh0000gn/T/ipykernel_8608/3524145327.py:11: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose =0)\n",
      "2022-03-01 13:22:15.850609: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43974763 0.77322253 0.55175962]\n"
     ]
    }
   ],
   "source": [
    "#define baseline model\n",
    "def baseline_model():\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 5, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    #compile model\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose =0)\n",
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "\n",
    "y_pred = cross_val_predict(estimator, X, Y)\n",
    "\n",
    "matrix = confusion_matrix(Y,y_pred)\n",
    "print(matrix.diagonal()/matrix.sum(axis=1))\n",
    "\n",
    "result = cross_validate(estimator, X, Y, scoring = 'f1_weighted')\n",
    "print(result['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "be1827e4546944a061b4268b628172683f2abe1595604765ff741e781e0d94c0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('environments': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
